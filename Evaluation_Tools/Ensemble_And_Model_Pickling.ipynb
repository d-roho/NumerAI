{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suBex3vnr5GO"
      },
      "source": [
        "# This notebook has two main functions:\n",
        "\n",
        "1. Pickle our pre-trained models to submit to the NumerAI Leaderboard\n",
        "2. Create an ensemble of our two best models - Autoencoder & LGBM\n",
        "\n",
        "This will help us identify the true performance of our model when used to make stock trading decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsl2z7mr5Gd"
      },
      "source": [
        "## 0. Explanation of Model Submission\n",
        "To participate in the tournament, you must submit live predictions every Tuesday-Saturday.\n",
        "\n",
        "To automate this process, you can simply:\n",
        "- Define your prediction pipeline as a function\n",
        "- Serialize your function using the `cloudpickle` library\n",
        "- Upload your model pickle file to Numerai\n",
        "- Let Numerai run your model to submit live predictions every day\n",
        "\n",
        "Read more about Model Uploads and other self-hosted automation options in our [docs](https://docs.numer.ai/numerai-tournament/submissions#automation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4bHP_BGr5Gd"
      },
      "outputs": [],
      "source": [
        "# Install all dependencies\n",
        "!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Original Models\n"
      ],
      "metadata": {
        "id": "Dghiqah1zQbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 LightGBM"
      ],
      "metadata": {
        "id": "5QBm2LiyyI4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load from model:\n",
        "\n",
        "import lightgbm as lgb\n",
        "import json\n",
        "import pandas as pd\n",
        "model = lgb.Booster(model_file='LGBM_Full.txt')\n",
        "feature_metadata = json.load(open(f\"features.json\"))\n",
        "feature_set = feature_metadata[\"feature_sets\"]['all']\n",
        "\n",
        "# Define your prediction pipeline as a function\n",
        "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "    live_predictions = model.predict(live_features[feature_set])\n",
        "    submission = pd.Series(live_predictions, index=live_features.index)\n",
        "    return submission.to_frame(\"prediction\")\n",
        "\n",
        "# Use the cloudpickle library to serialize your function\n",
        "import cloudpickle\n",
        "p = cloudpickle.dumps(predict)\n",
        "with open(\"predict.pkl\", \"wb\") as f:\n",
        "    f.write(p)\n",
        "\n",
        "# Download file if running in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('lgbm.pkl')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "9j7yLdH3kn6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iplRaPPLr5Gd"
      },
      "source": [
        "1.2 Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a394ebef-e97c-4df8-96c9-20d6a879a97f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Define the Swish activation function\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "# Define the Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, feature_dim, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 1500),\n",
        "            nn.BatchNorm1d(1500),\n",
        "            Swish(),\n",
        "            nn.Linear(1500, 1000),\n",
        "            nn.BatchNorm1d(1000),\n",
        "            Swish(),\n",
        "            nn.Linear(1000, 500),\n",
        "            nn.BatchNorm1d(500),\n",
        "            Swish(),\n",
        "            nn.Linear(500, encoding_dim),\n",
        "            nn.BatchNorm1d(encoding_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 500),\n",
        "            nn.BatchNorm1d(500),\n",
        "            Swish(),\n",
        "            nn.Linear(500, 1000),\n",
        "            nn.BatchNorm1d(1000),\n",
        "            Swish(),\n",
        "            nn.Linear(1000, 1500),\n",
        "            nn.BatchNorm1d(1500),\n",
        "            Swish(),\n",
        "            nn.Linear(1500, feature_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Define the MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, dropout_rate):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load Models\n",
        "dropout_rate = 0.4\n",
        "feature_dim = 2376  # Your feature dimension\n",
        "encoding_dim = 1000  # Your encoding dimension\n",
        "input_dim = feature_dim + encoding_dim  # Total input dimension for MLP\n",
        "\n",
        "autoencoder = Autoencoder(feature_dim, encoding_dim)\n",
        "mlp = MLP(input_dim, dropout_rate)\n",
        "\n",
        "autoencoder.load_state_dict(torch.load('autoencoder.pth')['autoencoder'])\n",
        "mlp.load_state_dict(torch.load('autoencoder.pth')['mlp'])\n",
        "\n",
        "autoencoder.eval()\n",
        "mlp.eval()\n",
        "\n",
        "import json\n",
        "feature_metadata = json.load(open(f\"features.json\"))\n",
        "feature_set = feature_metadata[\"feature_sets\"]['all']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Define your prediction pipeline as a function\n",
        "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Ensure the model is in the evaluation mode\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "    # Prepare the validation dataset\n",
        "    X_val_tensor = torch.tensor(live_features[feature_set].values, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(live_features['target'].values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    ## Make Predictions\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, _ in val_dataloader:\n",
        "            encoded, _ = autoencoder(data)  # Only encoded is needed for prediction\n",
        "            predictions = mlp(torch.cat((encoded, data), dim=1))\n",
        "            all_predictions.extend(predictions.numpy())\n",
        "\n",
        "    live_predictions = np.array(all_predictions).reshape(len(all_predictions),).tolist()\n",
        "\n",
        "    submission = pd.Series(live_predictions, index=live_features.index)\n",
        "    return submission.to_frame(\"prediction\")\n",
        "\n",
        "import cloudpickle\n",
        "p = cloudpickle.dumps(predict)\n",
        "with open(\"autoencoder.pkl\", \"wb\") as f:\n",
        "    f.write(p)\n",
        "\n",
        "# Download file if running in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('autoencoder.pkl')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2cOi9aRZmamJ",
        "outputId": "f532cac9-fe89-4fff-eb84-c7016fcef8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_51a6a838-00e4-4d5a-b475-8475ba878d13\", \"autoencoder.pkl\", 65276566)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 CNN"
      ],
      "metadata": {
        "id": "6608lIGAySg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Define CNN Class\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_features=32)\n",
        "        self.maxpool1 = nn.MaxPool1d(kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(num_features=64)\n",
        "        self.adaptive_avg_pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
        "        self.linear1 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.adaptive_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.linear1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        return x\n",
        "import json\n",
        "feature_metadata = json.load(open(f\"features.json\"))\n",
        "feature_set = feature_metadata[\"feature_sets\"]['all']\n",
        "\n",
        "\n",
        "# Load\n",
        "\n",
        "model = torch.load(\"/content/cnn.pt\", map_location=torch.device('cpu'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Ensure the model is in the evaluation mode\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "    # Prepare the validation dataset\n",
        "    X_val_tensor = torch.Tensor(live_features[feature_set].values)\n",
        "    y_val_tensor = torch.Tensor(live_features['target'].values)\n",
        "\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    ## Make Predictions\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, _ in val_dataloader:\n",
        "          features = features.unsqueeze(1)\n",
        "          predictions = model(features)\n",
        "          all_predictions.extend(predictions.numpy())\n",
        "\n",
        "        live_predictions = np.array(all_predictions).reshape(len(all_predictions),).tolist()\n",
        "\n",
        "        submission = pd.Series(live_predictions, index=live_features.index)\n",
        "        return submission.to_frame(\"prediction\")\n",
        "\n",
        "import cloudpickle\n",
        "p = cloudpickle.dumps(predict)\n",
        "with open(\"cnn.pkl\", \"wb\") as f:\n",
        "    f.write(p)\n",
        "\n",
        "# Download file if running in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('cnn.pkl')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6dc3e58d-1e04-4c6c-d767-e768ec2af270",
        "id": "RAUuKyt6_SKB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d39c3047-19f7-4262-8374-cbde5696fd89\", \"cnn.pkl\", 129879)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Define your prediction pipeline as a function\n",
        "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Ensure the model is in the evaluation mode\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "    # Prepare the validation dataset\n",
        "    X_val_tensor = torch.tensor(live_features[feature_set].values, dtype=torch.float32)\n",
        "    val_dataset = TensorDataset(X_val_tensor)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    ## Make Predictions\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in val_dataloader:\n",
        "            encoded, _ = autoencoder(data)  # Only encoded is needed for prediction\n",
        "            predictions = mlp(torch.cat((encoded, data), dim=1))\n",
        "            all_predictions.extend(predictions.numpy())\n",
        "\n",
        "    live_predictions = all_predictions.reshape(len(all_predictions),).tolist()\n",
        "\n",
        "    submission = pd.Series(live_predictions, index=live_features.index)\n",
        "    return submission.to_frame(\"prediction\")\n",
        "\n",
        "import cloudpickle\n",
        "p = cloudpickle.dumps(predict)\n",
        "with open(\"predict.pkl\", \"wb\") as f:\n",
        "    f.write(p)\n",
        "\n",
        "# Download file if running in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('predict.pkl')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "outputId": "56ef2c9b-5573-448e-ebd5-b9b06f74a6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "etckLRVMqGfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0753dc73-ebfd-468b-bd6b-52a50dfcde4c\", \"predict.pkl\", 65180155)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature Neutral & Ensemble Models"
      ],
      "metadata": {
        "id": "o5AGVoFxyz6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0 Defining Models and Functions"
      ],
      "metadata": {
        "id": "Gp6tEZNCzAl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-7OLNdmstHd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import json\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "# Define the Swish activation function\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "# Define the Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, feature_dim, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 1500),\n",
        "            nn.BatchNorm1d(1500),\n",
        "            Swish(),\n",
        "            nn.Linear(1500, 1000),\n",
        "            nn.BatchNorm1d(1000),\n",
        "            Swish(),\n",
        "            nn.Linear(1000, 500),\n",
        "            nn.BatchNorm1d(500),\n",
        "            Swish(),\n",
        "            nn.Linear(500, encoding_dim),\n",
        "            nn.BatchNorm1d(encoding_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 500),\n",
        "            nn.BatchNorm1d(500),\n",
        "            Swish(),\n",
        "            nn.Linear(500, 1000),\n",
        "            nn.BatchNorm1d(1000),\n",
        "            Swish(),\n",
        "            nn.Linear(1000, 1500),\n",
        "            nn.BatchNorm1d(1500),\n",
        "            Swish(),\n",
        "            nn.Linear(1500, feature_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Define the MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, dropout_rate):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load Models\n",
        "dropout_rate = 0.4\n",
        "feature_dim = 2376  # Your feature dimension\n",
        "encoding_dim = 1000  # Your encoding dimension\n",
        "input_dim = feature_dim + encoding_dim  # Total input dimension for MLP\n",
        "\n",
        "autoencoder = Autoencoder(feature_dim, encoding_dim)\n",
        "mlp = MLP(input_dim, dropout_rate)\n",
        "\n",
        "autoencoder.load_state_dict(torch.load('autoencoder.pth')['autoencoder'])\n",
        "mlp.load_state_dict(torch.load('autoencoder.pth')['mlp'])\n",
        "\n",
        "autoencoder.eval()\n",
        "mlp.eval()\n",
        "\n",
        "#load from model:\n",
        "lgb = lgb.Booster(model_file='LGBM_Full.txt')\n",
        "feature_metadata = json.load(open(f\"features.json\"))\n",
        "feature_set = feature_metadata[\"feature_sets\"]['all']\n",
        "\n",
        "\n",
        "import json\n",
        "feature_metadata = json.load(open(f\"features.json\"))\n",
        "feature_set = feature_metadata[\"feature_sets\"]['all']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 LGBM + Autoencoder ENSEMBLE"
      ],
      "metadata": {
        "id": "mrtrV-kQyqQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define your prediction pipeline as a function\n",
        "def predict_ensemble(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "    # #1 - LGBM\n",
        "\n",
        "    lgb_predictions = lgb.predict(live_features[feature_set])\n",
        "    lgb_predictions = pd.Series(lgb_predictions, index=live_features.index)\n",
        "\n",
        "    # #2 - Autoencoder\n",
        "\n",
        "    # Prepare the validation dataset\n",
        "    X_val_tensor = torch.tensor(live_features[feature_set].values, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(live_features['target'].values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    ## Make Predictions\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, _ in val_dataloader:\n",
        "            encoded, _ = autoencoder(data)  # Only encoded is needed for prediction\n",
        "            predictions = mlp(torch.cat((encoded, data), dim=1))\n",
        "            all_predictions.extend(predictions.numpy())\n",
        "\n",
        "    live_predictions = np.array(all_predictions).reshape(len(all_predictions),).tolist()\n",
        "\n",
        "    auto_predictions = pd.Series(live_predictions, index=live_features.index)\n",
        "    submission = lgb_predictions.add(auto_predictions, fill_value=0.5)/2\n",
        "\n",
        "    return submission.to_frame(\"prediction\")\n",
        "\n",
        "import cloudpickle\n",
        "p = cloudpickle.dumps(predict_ensemble)\n",
        "with open(\"ensemble.pkl\", \"wb\") as f:\n",
        "    f.write(p)\n",
        "\n",
        "# Download file if running in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('ensemble.pkl')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c8c10004-6fc7-47f5-e2c3-2255dc955969",
        "id": "fNwazJHQt2xn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_32dca409-11d1-43d5-9edd-63e56390519b\", \"ensemble.pkl\", 65391313)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JAsl2z7mr5Gd"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}